{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de _tweets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "import langid  \n",
    "from langdetect import detect \n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        #promotoresods les desea feliz año. Nuestro lu...\n",
       "1        Aplicación de un riego de agua depurada con en...\n",
       "2        ??Es lunes de estreno ????????\\nLos esperamos ...\n",
       "3        A una década para cumplir con los objetivos de...\n",
       "4        ???Nº 329\\n??#HomenajeAlMunicipalismo en el @S...\n",
       "                               ...                        \n",
       "25360    Documento #CEPAL examina las tendencias económ...\n",
       "25361    Ámsterdam demuestra que no es ninguna quimera ...\n",
       "25362    ¡Aprovecha tu tiempo de confinamiento! En el b...\n",
       "25363    Un pilar del mandato de la Fundación es promov...\n",
       "25364    Casa Valle Imperial                           ...\n",
       "Name: texto, Length: 25365, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es = pd.read_feather('../data/tweets_es')\n",
    "tweets = tweets_es['texto']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ámsterdam demuestra que no es ninguna quimera lo de salir de manera diferente a como entramos en esta crisis, a nivel económico y de #sostenibilidad, ¡toca romper con el modelo actual de consumo! https://t.co/lDA5sLHTsu\\n#COVID19'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweets[25361]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(tweet).detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langid.classify(tweet)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar tweets\n",
    "\n",
    "[Python NLTK: Twitter Sentiment Analysis [Natural Language Processing (NLP)]](https://blog.chapagain.com.np/python-nltk-twitter-sentiment-analysis-natural-language-processing-nlp/)\n",
    "\n",
    "1. Remove stock market tickers like $GE\n",
    "1. Remove retweet text “RT”\n",
    "1. Remove hyperlinks\n",
    "1. Remove hashtags (only the hashtag # and not the word)\n",
    "1. Remove stop words like a, and, the, is, are, etc.\n",
    "1. Remove emoticons like :), :D, :(, :-), etc.\n",
    "1. Remove punctuation like full-stop, comma, exclamation sign, etc.\n",
    "1. Convert words to Stem/Base words using Porter Stemming Algorithm. E.g. words like ‘working’, ‘works’, and ‘worked’ will be converted to their base/stem word “work”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'???Nº 329\\n??#HomenajeAlMunicipalismo en el @Senadoesp, #40AñosDeDemocraciaLocal. \\n??La #FEMP en #COP25\\n??Poniendo cara a los #ODS, casos prácticos: #ODS2.\\n\\n??https://t.co/HiejHrKUOZ https://t.co/fAeD4UUfEx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweets[4]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones cogidas de [Word embeddings with code2vec, GloVe, and spaCy](https://towardsdatascience.com/word-embeddings-with-code2vec-glove-and-spacy-5b26420bf632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case(example):      \n",
    "    if  any(x in example for x  in string.punctuation)==True:\n",
    "        return False\n",
    "    else:\n",
    "        if any(list(map(str.isupper, example[1:-1]))) and not all(list(map(str.isupper, example[1:-1]))):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def camel_case_split(word):\n",
    "    idx = list(map(str.isupper, word))\n",
    "    case_change = [0]\n",
    "    for (i, (x, y)) in enumerate(zip(idx, idx[1:])):\n",
    "        if x and not y:  \n",
    "            case_change.append(i)\n",
    "        elif not x and y:  \n",
    "            case_change.append(i+1)\n",
    "    case_change.append(len(word))\n",
    "    return [word[x:y] for x, y in zip(case_change, case_change[1:]) if x < y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HomenajeAlMunicipalismo', 'FEMP', 'COP', 'ODS', 'ODS']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word[1:] for word in re.findall(r'#[a-zA-Z]+', tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[camel_case(word[1:]) for word in re.findall(r'#[a-zA-Z]+', tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HomenajeAlMunicipalismo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word[1:] for word in re.findall(r'#[a-zA-Z]+', tweet) if camel_case(word[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Homenaje Al Municipalismo']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(camel_case_split(word[1:])) for word in re.findall(r'#[a-zA-Z]+', tweet) if camel_case(word[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    " \n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"es\")\n",
    " \n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "# Punctuation\n",
    "punctuation = string.punctuation\n",
    "punctuation += '¿¡'\n",
    "\n",
    "# Add stop words\n",
    "stopwords_spanish = STOP_WORDS\n",
    "stopwords_spanish.update(['covid19'])\n",
    "\n",
    "# Noise words\n",
    "noise_words = stopwords_spanish.union(emoticons)\n",
    "noise_words = noise_words.union(set([c for c in punctuation]))\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove users\n",
    "    tweet = re.sub(r'@[a-zA-Z0-9]+', '', tweet)\n",
    "    \n",
    "    # split camel case\n",
    "    camel_case_words = [word[1:] for word in re.findall(r'#[a-zA-Z]+', tweet) if camel_case(word[1:])]\n",
    "    splited_words = [' '.join(camel_case_split(word[1:])) for word in re.findall(r'#[a-zA-Z]+', tweet) if camel_case(word[1:])]\n",
    "    for camel, splited in zip(camel_case_words, splited_words):\n",
    "        tweet = tweet.replace(camel, splited)\n",
    "\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # remove single letters\n",
    "    tweet = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", tweet)\n",
    " \n",
    "    # remove multiple spaces\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet)\n",
    "\n",
    "    # tokenize tweets\n",
    "    tweet_tokens = nlp(tweet)\n",
    " \n",
    "    #tweets_clean = [word.lemma_ for word in tweet_tokens if word.text not in noise_words]    \n",
    "    \n",
    "    tweets_clean = [word.lemma_ for word in tweet_tokens if not word.is_stop and word.pos_ != 'PUNCT']\n",
    " \n",
    "    return ' '.join(tweets_clean).lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nº 329 homenaje municipalismo 40añosdedemocracialocal femp cop25 poniendo caro ods caso práctico ods2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 133 ms, total: 3min\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_limpios = tweets.apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        promotoresods desear feliz año necesitar esper...\n",
       "1        aplicación regar aguar depurar enzima natural ...\n",
       "2        lunes estrenar esperar 19:30 _ 13c viajar para...\n",
       "3        década cumplir objetivo agenda2030 preparar en...\n",
       "4        nº 329 homenaje municipalismo 40añosdedemocrac...\n",
       "                               ...                        \n",
       "25360    documento cepal examinar tendencia económico s...\n",
       "25361    ámsterdam demostrar quimera salir entrar crisi...\n",
       "25362    aprovecha confinamiento blog encontrar 40 artí...\n",
       "25363    pilar mandato fundación promover debatir ue al...\n",
       "25364    casa valle imperial proyectar integración tecn...\n",
       "Name: texto, Length: 25365, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tweets_limpios.values, columns=['text']).to_feather('../data/tweets_limpios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado de categorías\n",
    "\n",
    "[Ultimate Guide to Understand and Implement Natural Language Processing (with codes in Python)](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [doc.split() for doc in tweets_limpios]\n",
    "dictionary = corpora.Dictionary(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 42s, sys: 5.94 ms, total: 3min 42s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=17, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.047*\"empresa\" + 0.047*\"rsc\" + 0.043*\"sostenibilidad\" + 0.037*\"ods\" + 0.024*\"virtual\" + 0.018*\"relacionar\" + 0.017*\"nacional\" + 0.016*\"gracia\" + 0.016*\"compromiso\" + 0.016*\"rse\"'),\n",
       " (1,\n",
       "  '0.113*\"_\" + 0.079*\"ods\" + 0.052*\"agenda2030\" + 0.032*\"igualdad\" + 0.027*\"mujer\" + 0.022*\"género\" + 0.012*\"niño\" + 0.012*\"foro\" + 0.011*\"gracias\" + 0.011*\"importancia\"'),\n",
       " (2,\n",
       "  '0.080*\"ods\" + 0.076*\"sostenible\" + 0.057*\"desarrollo\" + 0.053*\"agenda2030\" + 0.037*\"objetivos\" + 0.022*\"planeta\" + 0.021*\"desarrollar\" + 0.020*\"objetivo\" + 0.014*\"sociedad\" + 0.013*\"lograr\"'),\n",
       " (3,\n",
       "  '0.085*\"sostenibilidad\" + 0.027*\"sostenible\" + 0.025*\"jornada\" + 0.021*\"organizar\" + 0.018*\"sector\" + 0.012*\"producto\" + 0.012*\"naturaleza\" + 0.012*\"the\" + 0.011*\"centro\" + 0.011*\"educativo\"'),\n",
       " (4,\n",
       "  '0.106*\"sostenibilidad\" + 0.023*\"casa\" + 0.023*\"sostenible\" + 0.020*\"innovación\" + 0.015*\"_\" + 0.013*\"social\" + 0.011*\"tecnología\" + 0.010*\"movilidad\" + 0.010*\"verde\" + 0.010*\"congreso\"'),\n",
       " (5,\n",
       "  '0.039*\"educación\" + 0.032*\"mejorar\" + 0.028*\"aprendizaje\" + 0.027*\"calidad\" + 0.021*\"consciente\" + 0.019*\"tech\" + 0.018*\"sostenibilidad\" + 0.017*\"colombia\" + 0.017*\"cartagena\" + 0.016*\"ods5\"'),\n",
       " (6,\n",
       "  '0.047*\"energía\" + 0.042*\"aguar\" + 0.038*\"temer\" + 0.033*\"reflexionar\" + 0.028*\"agua\" + 0.025*\"abril\" + 0.019*\"consejo\" + 0.018*\"renovable\" + 0.017*\"servicio\" + 0.015*\"ecuador\"'),\n",
       " (7,\n",
       "  '0.050*\"iniciativo\" + 0.047*\"ods\" + 0.045*\"sostenibilidad\" + 0.040*\"práctico\" + 0.038*\"social\" + 0.035*\"rse\" + 0.030*\"responsable\" + 0.028*\"seguridad\" + 0.024*\"responsabilidad\" + 0.023*\"materia\"'),\n",
       " (8,\n",
       "  '0.040*\"ods\" + 0.025*\"mundo\" + 0.023*\"mundial\" + 0.022*\"sostenibilidad\" + 0.021*\"internacional\" + 0.021*\"año\" + 0.020*\"agenda2030\" + 0.017*\"líder\" + 0.014*\"millón\" + 0.014*\"formación\"'),\n",
       " (9,\n",
       "  '0.068*\"ods\" + 0.064*\"agenda2030\" + 0.036*\"_\" + 0.031*\"agenda\" + 0.020*\"2030\" + 0.018*\"cuba\" + 0.016*\"universidad\" + 0.016*\"social\" + 0.015*\"implementación\" + 0.010*\"gestión\"'),\n",
       " (10,\n",
       "  '0.045*\"sostenibilidad\" + 0.036*\"_\" + 0.031*\"sdg\" + 0.028*\"ods\" + 0.020*\"aprender\" + 0.020*\"tomar\" + 0.019*\"estrategia\" + 0.018*\"turismo\" + 0.015*\"herramienta\" + 0.015*\"webinar\"'),\n",
       " (11,\n",
       "  '0.065*\"”\" + 0.051*\"ods\" + 0.045*\"“\" + 0.038*\"salud\" + 0.032*\"agenda2030\" + 0.031*\"3\" + 0.025*\"bienestar\" + 0.014*\"2\" + 0.014*\"combatir\" + 0.013*\"ver\"'),\n",
       " (12,\n",
       "  '0.071*\"sostenibilidad\" + 0.022*\"cuidar\" + 0.019*\"ambientar\" + 0.017*\"ambiental\" + 0.017*\"poder\" + 0.015*\"responsable\" + 0.015*\"casar\" + 0.015*\"semana\" + 0.015*\"medioambiente\" + 0.014*\"consumir\"'),\n",
       " (13,\n",
       "  '0.066*\"ods\" + 0.058*\"agenda2030\" + 0.025*\"hora\" + 0.022*\"económico\" + 0.021*\"online\" + 0.019*\"encontrar\" + 0.017*\"crecimiento\" + 0.017*\"social\" + 0.015*\"objetivar\" + 0.015*\"onu\"'),\n",
       " (14,\n",
       "  '0.023*\"&\" + 0.020*\"frente\" + 0.018*\"ods\" + 0.016*\"sostenibilidad\" + 0.015*\"fundamental\" + 0.014*\"sdgs\" + 0.014*\"conocimiento\" + 0.014*\"17\" + 0.014*\"febrero\" + 0.013*\"gt\"'),\n",
       " (15,\n",
       "  '0.094*\"sostenibilidad\" + 0.051*\"cambiar\" + 0.048*\"climático\" + 0.045*\"cambio\" + 0.044*\"crisis\" + 0.034*\"medioambiente\" + 0.022*\"economía\" + 0.019*\"pensar\" + 0.018*\"biodiversidad\" + 0.017*\"ambiente\"'),\n",
       " (16,\n",
       "  '0.031*\"gratuito\" + 0.030*\"+\" + 0.028*\"basar\" + 0.026*\"cursar\" + 0.025*\"desarrollar\" + 0.025*\"marzo\" + 0.019*\"liderazgo\" + 0.019*\"ods\" + 0.016*\"abrir\" + 0.015*\"sostenibilidad\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics(num_topics=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
